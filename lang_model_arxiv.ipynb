{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lang_model-arxiv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/x110/MyFastaiNotebooks/blob/master/lang_model_arxiv.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kzKJe-kPBBJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "metadata": {
        "id": "jMvnpkmFhU3g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ]
    },
    {
      "metadata": {
        "id": "vgKSosPCWryv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "The sentiment classification task consists of predicting the polarity (positive or negative) of a given text. \n"
      ]
    },
    {
      "metadata": {
        "id": "DILLqWO1h1Eo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Dataset\n",
        "The [large moview view dataset](http://files.fast.ai/data/aclImdb.tgz) contains a collection of 50,000 reviews from IMDB. The datset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score $\\leq 4$ out of 10, a positive review has a score $\\geq 7$ out of 10. Nuteral reviews are not included in this dataset, \n",
        "The dataset we are using is the IMDb movie review dataset. \"This is a dataset of binary sentiment classification. It contains a set of 25,000 higly polar movie reviews for training, and 25,000 for testing.  "
      ]
    },
    {
      "metadata": {
        "id": "biVkRx7oXI7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution Strategy\n",
        "Before we try to classify sentiment, we will try to create a language model; that is, a model that can predict the next word in a sentence. Why? Because our model first needs to understand the structure of English, before we can expect it to recognize positive or negative sentiment. "
      ]
    },
    {
      "metadata": {
        "id": "_Zw1OmAdTNIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare virtual machine on google colab\n"
      ]
    },
    {
      "metadata": {
        "id": "DVsW1SvC083b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Connect to google drive\n",
        "2. Install dependencies"
      ]
    },
    {
      "metadata": {
        "id": "08t5SP8x_zet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ede5c62-302f-4bdb-cd71-22368c4cbce5"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb.tgz  aclImdb.tgz.1  aclImdb.tgz.2  data  datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wnQn8DdaANtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2d8f7ce7-b998-464d-a35a-e4d7a4a73846"
      },
      "cell_type": "code",
      "source": [
        "## Connect to google drive for storage \n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmp6ykv0zxs/pubring.gpg' created\n",
            "gpg: /tmp/tmp6ykv0zxs/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NyB38mu1ARiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        },
        "outputId": "9f322424-dd68-435d-bab0-ac23ee0eb3bb"
      },
      "cell_type": "code",
      "source": [
        "#Install dependencies\n",
        "!pip install https://github.com/fastai/fastai/archive/master.zip\n",
        "!pip install opencv-python\n",
        "!apt update && apt install -y libsm6 libxext6\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "!pip install kaggle"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/fastai/fastai/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/fastai/fastai/archive/master.zip (90.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 90.0MB 801kB/s \n",
            "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): fastai==0.7.0 from https://github.com/fastai/fastai/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: bcolz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.4.16)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.3)\n",
            "Requirement already satisfied: feather-format in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.3)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (7.2.1)\n",
            "Requirement already satisfied: isoweek in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.3.3)\n",
            "Requirement already satisfied: jedi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.12.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.1.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Requirement already satisfied: pandas_summary in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.0.41)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.6.0)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.12)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (16.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.19.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.1)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: sklearn_pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)\n",
            "Requirement already satisfied: torch<0.4 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.0.post4)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.23.4)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bleach->fastai==0.7.0) (1.11.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format->fastai==0.7.0) (0.9.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (39.1.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: parso>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from jedi->fastai==0.7.0) (0.2.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (4.3.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.3.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.45.1)\n",
            "Requirement already satisfied: mizani>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.4.6)\n",
            "Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas->fastai==0.7.0) (0.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (from mizani>=0.4.1->plotnine->fastai==0.7.0) (3.1.1)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Building wheels for collected packages: fastai\n",
            "  Running setup.py bdist_wheel for fastai ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-oo0josb2/wheels/64/3d/9f/d12a217aa2531321c5b9ae96288fcae2687d3b744376e8f94f\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully built fastai\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.1.15)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.5)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Hit:1 http://security.ubuntu.com/ubuntu artful-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu artful InRelease\n",
            "Hit:3 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu artful InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu artful-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu artful-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.2-1).\n",
            "libxext6 is already the newest version (2:1.3.3-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.5)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/5f/4b/8b54ab9d37b93998c81b364557dff9f61972c0f650efa0ceaf470b392740/Pillow-5.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.12)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.1.0\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.23.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SxOW0mgcAw45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "6a7e022a-e8af-46c5-da05-3fd2aa5e021c"
      },
      "cell_type": "code",
      "source": [
        "#install More dependencies\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "!apt-get install p7zip-full"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.45.1)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.1.0\n",
            "    Uninstalling Pillow-5.1.0:\n",
            "      Successfully uninstalled Pillow-5.1.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.24)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.0.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.45.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.4)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DS8qplKOApM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3124791-5a15-43e0-ae3c-64af6f45ca15"
      },
      "cell_type": "code",
      "source": [
        "!mkdir .kaggle\n",
        "!cp drive/kaggle.json /content/.kaggle/\n",
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xawiT4oGBwZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "d17d44e6-f529-485a-8591-80e0597d3b9c"
      },
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.5)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\n",
            "Requirement already satisfied: thinc<6.11.0,>=6.10.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (4.23.4)\n",
            "Requirement already satisfied: msgpack-numpy==0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.4.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: cytoolz<0.9,>=0.8 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.8.2)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: msgpack-python in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: spacy\n",
            "Successfully installed spacy-2.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYn2kVpsXOpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloads"
      ]
    },
    {
      "metadata": {
        "id": "fBR3j5Boi0j4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download the weights of the trained language model"
      ]
    },
    {
      "metadata": {
        "id": "JNqeEKwnuXUB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#already in drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7p48ALaWWF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "id": "F-P9YN_NrExZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "13591d64-6936-42be-f4f8-69202b7a93b5"
      },
      "cell_type": "code",
      "source": [
        "!wget http://files.fast.ai/data/aclImdb.tgz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-30 06:47:08--  http://files.fast.ai/data/aclImdb.tgz\r\n",
            "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\r\n",
            "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145982645 (139M) [text/plain]\n",
            "Saving to: ‘aclImdb.tgz.1’\n",
            "\n",
            "aclImdb.tgz.1       100%[===================>] 139.22M  91.9MB/s    in 1.5s    \n",
            "\n",
            "2018-06-30 06:47:10 (91.9 MB/s) - ‘aclImdb.tgz.1’ saved [145982645/145982645]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0gdRrr_4eXTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WvyNIx5nqhNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xzf aclImdb.tgz\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ve0yGuGRkM5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv aclImdb\tdata/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CvhAAzphZVKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run model under 10 min"
      ]
    },
    {
      "metadata": {
        "id": "lhb1GtFxA9BQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "SQFYrlasA9Jy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.model import fit\n",
        "from fastai.dataset import *\n",
        "\n",
        "import torchtext\n",
        "from torchtext import vocab, data\n",
        "from torchtext.datasets import language_modeling\n",
        "\n",
        "from fastai.rnn_reg import *\n",
        "from fastai.rnn_train import *\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "import dill as pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGIiClVQPdNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language modeling\n",
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "DSTxMa_gC9wU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d4459c9-752e-49b8-b655-becef7506e99"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb.tgz  aclImdb.tgz.1  aclImdb.tgz.2  data  datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fvsImsj_jLaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "311bb3a3-1d06-441a-b188-a958b2b8d923"
      },
      "cell_type": "code",
      "source": [
        "PATH = 'data/aclImdb/'\n",
        "TRN_PATH = 'train/all/'\n",
        "VAL_PATH = 'test/all/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdbEr.txt  imdb.vocab  README  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBHvZCEqk92G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b6f43f25-256e-4cc1-c428-4fe6e000d2c1"
      },
      "cell_type": "code",
      "source": [
        "trn_files = !ls {TRN}\n",
        "trn_files[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0_0.txt',\n",
              " '0_3.txt',\n",
              " '0_9.txt',\n",
              " '10000_0.txt',\n",
              " '10000_4.txt',\n",
              " '10000_8.txt',\n",
              " '1000_0.txt',\n",
              " '10001_0.txt',\n",
              " '10001_10.txt',\n",
              " '10001_4.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "SjpJMi1xpwWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a8e4c948-2925-4dd7-da54-417546b55f83"
      },
      "cell_type": "code",
      "source": [
        "review=!cat {TRN}{trn_files[6]}\n",
        "review[0] "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I have to say when a name like Zombiegeddon and an atom bomb on the front cover I was expecting a flat out chop-socky fung-ku, but what I got instead was a comedy. So, it wasn't quite was I was expecting, but I really liked it anyway! The best scene ever was the main cop dude pulling those kids over and pulling a Bad Lieutenant on them!! I was laughing my ass off. I mean, the cops were just so bad! And when I say bad, I mean The Shield Vic Macky bad. But unlike that show I was laughing when they shot people and smoked dope.<br /><br />Felissa Rose...man, oh man. What can you say about that hottie. She was great and put those other actresses to shame. She should work more often!!!!! I also really liked the fight scene outside of the building. That was done really well. Lots of fighting and people getting their heads banged up. FUN! Last, but not least Joe Estevez and William Smith were great as the...well, I wasn't sure what they were, but they seemed to be having fun and throwing out lines. I mean, some of it didn't make sense with the rest of the flick, but who cares when you're laughing so hard! All in all the film wasn't the greatest thing since sliced bread, but I wasn't expecting that. It was a Troma flick so I figured it would totally suck. It's nice when something surprises you but not totally sucking.<br /><br />Rent it if you want to get stoned on a Friday night and laugh with your buddies. Don't rent it if you are an uptight weenie or want a zombie movie with lots of flesh eating.<br /><br />P.S. Uwe Boil was a nice touch.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "Xt-D-bhiuqcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df83144a-3485-4527-af0d-cc0db2d041c8"
      },
      "cell_type": "code",
      "source": [
        "!find {TRN} -name \"*.txt\" | xargs cat| wc -w"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17486581\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i83aFD9m0AtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8c1cc9f-45bb-4e98-ee0e-c87d6d177651"
      },
      "cell_type": "code",
      "source": [
        "!find {VAL} -name \"*.txt\" | xargs cat | wc -w"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5686719\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ln5-Mv3d1gTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "3786a804-501f-4a31-dbe4-dd227534e1bf"
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 40.6MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-UEulfR93Cn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spacy_tok=spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzpPE48Qf5ea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26c04eba-50ec-4664-8c77-27b70ef4f951"
      },
      "cell_type": "code",
      "source": [
        "spacy_tok"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7fbce50f0940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "jeGfdA6V0ViM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "59dfc83a-371d-4d9d-de6a-9a89ea514f41"
      },
      "cell_type": "code",
      "source": [
        "' '.join(str(v) for v in spacy_tok(review[0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I have to say when a name like Zombiegeddon and an atom bomb on the front cover I was expecting a flat out chop - socky fung - ku , but what I got instead was a comedy . So , it was n't quite was I was expecting , but I really liked it anyway ! The best scene ever was the main cop dude pulling those kids over and pulling a Bad Lieutenant on them ! ! I was laughing my ass off . I mean , the cops were just so bad ! And when I say bad , I mean The Shield Vic Macky bad . But unlike that show I was laughing when they shot people and smoked dope.<br /><br />Felissa Rose ... man , oh man . What can you say about that hottie . She was great and put those other actresses to shame . She should work more often ! ! ! ! ! I also really liked the fight scene outside of the building . That was done really well . Lots of fighting and people getting their heads banged up . FUN ! Last , but not least Joe Estevez and William Smith were great as the ... well , I was n't sure what they were , but they seemed to be having fun and throwing out lines . I mean , some of it did n't make sense with the rest of the flick , but who cares when you 're laughing so hard ! All in all the film was n't the greatest thing since sliced bread , but I was n't expecting that . It was a Troma flick so I figured it would totally suck . It 's nice when something surprises you but not totally sucking.<br /><br />Rent it if you want to get stoned on a Friday night and laugh with your buddies . Do n't rent it if you are an uptight weenie or want a zombie movie with lots of flesh eating.<br /><br />P.S. Uwe Boil was a nice touch .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Kh2m3mgZ0dvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEXT=data.Field(lower=True,tokenize='spacy')#spacy_tok)#https://github.com/fastai/fastai/issues/213"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucFg6eWc43lQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9103c23e-c20a-41f5-9fd5-cbb49735db4f"
      },
      "cell_type": "code",
      "source": [
        "type(list(spacy_tok(review[0]))[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "FnNmA22N5EQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs=64;bptt=70"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95DVQjwj6yoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FILES=dict(train=TRN_PATH,validation=VAL_PATH,test=VAL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ITlD5hQ701b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "712832da-33a3-4e51-99a9-e0efbdd1b20e"
      },
      "cell_type": "code",
      "source": [
        "%time md = LanguageModelData.from_text_files(PATH,TEXT,**FILES,bs=bs,bptt=bptt,min_freq=10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14min 55s, sys: 7.39 s, total: 15min 2s\n",
            "Wall time: 15min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "po2bETWi8VM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "289c9833-4ff1-4dfa-9b0b-ac9b8a8489dd"
      },
      "cell_type": "code",
      "source": [
        "md.nt"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "Pckf6AAIhEtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00546ab1-5cef-4fe2-aab6-6596f12918ec"
      },
      "cell_type": "code",
      "source": [
        "!ls data/aclImdb"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "shWzP7OC8XL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f66dd645-b603-4661-ba9d-5bd9a0c41925"
      },
      "cell_type": "code",
      "source": [
        "!mkdir {PATH}models\n",
        "\n",
        "pickle.dump(TEXT,open(f'{PATH}models/TEXT.pkl','wb'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data/aclImdb/models’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ECE4DT9eO1AM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "997a7f14-a94c-48d5-c602-b834d3a85a67"
      },
      "cell_type": "code",
      "source": [
        "len(md.trn_dl),md.nt,len(md.trn_ds),len(md.trn_ds[0].text)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4583, 37392, 1, 20540756)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "FC9XG2iFZd0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RU9md5zxQbYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the start of the mapping from integer IDs to unique tokens"
      ]
    },
    {
      "metadata": {
        "id": "TAoA_iHKQPqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56bd58cf-441e-436b-85c8-f71425f97f4c"
      },
      "cell_type": "code",
      "source": [
        "#'itoi':'string to int'\n",
        "TEXT.vocab.itos[:12]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "E9Tgc5V9Q8vA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "230e138d-1f35-48f5-8a8c-5763af633200"
      },
      "cell_type": "code",
      "source": [
        "TEXT.vocab.stoi['the']"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "nQsT01bvRXuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that in a languageModelData object there is only one item in each dataset: all words of the text joined together"
      ]
    },
    {
      "metadata": {
        "id": "vfUQb882RKKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "a3cc79e1-fb07-4454-e115-3201d7a0ca5d"
      },
      "cell_type": "code",
      "source": [
        "md.trn_ds[0].text[:12]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " \"'ll\",\n",
              " 'keep',\n",
              " 'this',\n",
              " 'short',\n",
              " 'and',\n",
              " 'sweet',\n",
              " ':',\n",
              " 'anyone',\n",
              " 'who',\n",
              " 'found',\n",
              " 'himself']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "pi2de_TpaYF3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "torchtext will handle turning these words into integer IDs for us automatically"
      ]
    },
    {
      "metadata": {
        "id": "OgPItleyVseV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d598cddd-4acc-4463-f6fd-21306a743c04"
      },
      "cell_type": "code",
      "source": [
        "TEXT.numericalize([md.trn_ds[0].text[0:12]])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "   12\n",
              "  259\n",
              "  398\n",
              "   13\n",
              "  370\n",
              "    5\n",
              " 1096\n",
              "   94\n",
              "  272\n",
              "   43\n",
              "  268\n",
              "  331\n",
              "[torch.cuda.LongTensor of size 12x1 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "TzgjdisFcFha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our language model object will create batches with 64 columns ,and varying sequence lengths of around 70 tokens.\n",
        "\n",
        "Each batch also contains the exact sane data as labels,but one word later than the text since we are trying to predict the next words. the labels are flatten into a 1d array."
      ]
    },
    {
      "metadata": {
        "id": "JkOqIfVLawlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "76bd0ecc-15d0-42c9-9ae9-23578b7e9d17"
      },
      "cell_type": "code",
      "source": [
        "next(iter(md.trn_dl))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Variable containing:\n",
              "     12   1414     71  ...    1478     38     48\n",
              "    259      4      5  ...   25375     46      2\n",
              "    398     24  30853  ...       3      2    925\n",
              "         ...            ⋱           ...         \n",
              "      5   2437     10  ...     337    151      2\n",
              "      2    290      6  ...       8     80  14278\n",
              "     77      8  15931  ...    7534     59     12\n",
              " [torch.cuda.LongTensor of size 75x64 (GPU 0)], Variable containing:\n",
              "    259\n",
              "      4\n",
              "      5\n",
              "   ⋮   \n",
              "     10\n",
              "   4457\n",
              "  24458\n",
              " [torch.cuda.LongTensor of size 4800 (GPU 0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "F7jZPvb6d5IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "spJNDTJadIpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "em_sz=200#size of each embedding vector\n",
        "nh=500 #number of hidden activation per layer\n",
        "nl = 3 #number of layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGn5JVDpegNh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Researchers have found that large amounts of momentum dont work well with these kinds of RNN models, so we create a versio of adam optimizerwith less momentum than its default of .9"
      ]
    },
    {
      "metadata": {
        "id": "Qb39uOzLeOj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_fn = partial(optim.Adam,betas=(.7,.99))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pb_ABiCHh6li",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fastai uses a variant of the state of the art AWD LSTM Language model developed by Stephen Merity. A key feature of that model is that it provides excellent regularization through dropout. \n",
        "\n",
        "The other parameters (alpha, beta, clip) should not generally need tuning."
      ]
    },
    {
      "metadata": {
        "id": "dQWx4oYgfJ08",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner = md.get_model(opt_fn,em_sz,nh,nl,\n",
        "                      dropouti=.05, dropout = .05, wdrop=.1, dropoute=.02, dropouth=.05)\n",
        "learner.reg_fn = partial(seq2seq_reg,alpha=2,beta=1)\n",
        "learner.clip=.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZLFenNJmU1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "f1a21fc7-1245-43aa-f1a4-dec40c2aba11"
      },
      "cell_type": "code",
      "source": [
        "learner"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): RNN_Encoder(\n",
              "    (encoder): Embedding(37392, 200, padding_idx=1)\n",
              "    (encoder_with_dropout): EmbeddingDropout(\n",
              "      (embed): Embedding(37392, 200, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDrop(\n",
              "        (module): LSTM(200, 500)\n",
              "      )\n",
              "      (1): WeightDrop(\n",
              "        (module): LSTM(500, 500)\n",
              "      )\n",
              "      (2): WeightDrop(\n",
              "        (module): LSTM(500, 200)\n",
              "      )\n",
              "    )\n",
              "    (dropouti): LockedDropout(\n",
              "    )\n",
              "    (dropouths): ModuleList(\n",
              "      (0): LockedDropout(\n",
              "      )\n",
              "      (1): LockedDropout(\n",
              "      )\n",
              "      (2): LockedDropout(\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=200, out_features=37392)\n",
              "    (dropout): LockedDropout(\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "QnExVwolm-lJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bb608bc8-5c6f-402b-d953-132eeea53d56"
      },
      "cell_type": "code",
      "source": [
        "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ce8889b399a435e900ab69f7fff62ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      5.117613   5.003315  \n",
            " 17%|█▋        | 781/4583 [03:47<18:27,  3.43it/s, loss=5.05]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      4.779484   4.641753  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      4.662469   4.551414  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    3      4.660255   4.524417  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      4.565983   4.443225  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      4.504306   4.386119  \n",
            " 50%|█████     | 2292/4583 [11:14<11:14,  3.40it/s, loss=4.46]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LZJnV65zn88Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.save_encoder(\"adam1_enc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CI2YVzxIHsTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp data/aclImdb/models/adam1_enc.h5 drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6bVOypYn8zc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.load_encoder(\"adam1_enc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlvMgtI8n8ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#learner.load_cycle('adam1_enc',2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mnkzKqpn8fN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e89f416e-7656-4581-c881-01a8a758d1e0"
      },
      "cell_type": "code",
      "source": [
        "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a8948249564cd18663506c00186425",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      4.511491   4.389013  \n",
            " 17%|█▋        | 782/4583 [03:49<18:37,  3.40it/s, loss=4.49]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      4.48086    4.374584  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    2      4.467634   4.357195  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    3      4.443721   4.333606  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    4      4.411171   4.310105  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    5      4.406945   4.291477  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    6      4.354332   4.270876  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    7      4.337243   4.256666  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    8      4.315477   4.248435  \n",
            " 57%|█████▋    | 2624/4583 [12:52<09:36,  3.40it/s, loss=4.3]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bWPbUELXn8WB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.save_encoder('adam3_10_enc')\n",
        "!cp data/aclImdb/models/adam3_10_enc.h5 drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EhmzwLmHn8CU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "math.exp(4.165)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wR1QVCLhn7r2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCwojFsvs6GA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42c3e020-7564-4a58-d61a-abc108a24867"
      },
      "cell_type": "code",
      "source": [
        "#uncomment to refresh google drive\n",
        "!google-drive-ocamlfuse -cc"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing cache...done\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWLtjjbwmV_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp drive/imdb_adam3_c1_cl10_cyc_0.h5 data/aclImdb/models/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "md09RDupSi4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "a07ba591-3990-4abb-e3ca-d1ab986aaea1"
      },
      "cell_type": "code",
      "source": [
        "learner.model.named_parameters"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_parameters of SequentialRNN(\n",
              "  (0): RNN_Encoder(\n",
              "    (encoder): Embedding(37392, 200, padding_idx=1)\n",
              "    (encoder_with_dropout): EmbeddingDropout(\n",
              "      (embed): Embedding(37392, 200, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDrop(\n",
              "        (module): LSTM(200, 500)\n",
              "      )\n",
              "      (1): WeightDrop(\n",
              "        (module): LSTM(500, 500)\n",
              "      )\n",
              "      (2): WeightDrop(\n",
              "        (module): LSTM(500, 200)\n",
              "      )\n",
              "    )\n",
              "    (dropouti): LockedDropout(\n",
              "    )\n",
              "    (dropouths): ModuleList(\n",
              "      (0): LockedDropout(\n",
              "      )\n",
              "      (1): LockedDropout(\n",
              "      )\n",
              "      (2): LockedDropout(\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=200, out_features=37392)\n",
              "    (dropout): LockedDropout(\n",
              "    )\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "hK9-rlWRRwvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "e4ec6bff-bdba-430a-d6d7-833f08ea25dc"
      },
      "cell_type": "code",
      "source": [
        "md.nt = 34945\n",
        "learner"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): RNN_Encoder(\n",
              "    (encoder): Embedding(37392, 200, padding_idx=1)\n",
              "    (encoder_with_dropout): EmbeddingDropout(\n",
              "      (embed): Embedding(37392, 200, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDrop(\n",
              "        (module): LSTM(200, 500)\n",
              "      )\n",
              "      (1): WeightDrop(\n",
              "        (module): LSTM(500, 500)\n",
              "      )\n",
              "      (2): WeightDrop(\n",
              "        (module): LSTM(500, 200)\n",
              "      )\n",
              "    )\n",
              "    (dropouti): LockedDropout(\n",
              "    )\n",
              "    (dropouths): ModuleList(\n",
              "      (0): LockedDropout(\n",
              "      )\n",
              "      (1): LockedDropout(\n",
              "      )\n",
              "      (2): LockedDropout(\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=200, out_features=37392)\n",
              "    (dropout): LockedDropout(\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "4bvBehfRQjum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "1e013fb0-e229-45d2-d547-04a37b0b8228"
      },
      "cell_type": "code",
      "source": [
        "learner.load('imdb_adam3_c1_cl10_cyc_0')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: sizes do not match at /pytorch/torch/lib/THC/generic/THCTensorCopy.c:51",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-69866d51d4ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb_adam3_c1_cl10_cyc_0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
            "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named 0.encoder.weight, whose dimensions in the model are torch.Size([37392, 200]) and whose dimensions in the checkpoint are torch.Size([34945, 200])."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "EkoP7C4_pKHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "decd9338-943a-4dd6-c542-f93c28c6f422"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/*.h5"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/imdb2x_cyc_4.h5  drive/imdb_adam3_c1_cl10_cyc_0.h5  drive/resnet_75.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jbhh12bQvAf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnjMW3GuaHG7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train from scratch (including training the language model)\n"
      ]
    },
    {
      "metadata": {
        "id": "gRmoC7QlaeBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.learner import *\n",
        "\n",
        "import torchtext\n",
        "from torchtext import vocab , data\n",
        "from torchtext.datasets import language_modeling\n",
        "\n",
        "from fastai.rnn_reg import*\n",
        "from fastai.rnn_train import *\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "import dill as pickle\n",
        "import spacy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mxVaqsOb4uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Language modeling"
      ]
    },
    {
      "metadata": {
        "id": "IhRmex7KeBRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b446c36-1d92-4396-dc00-ad487981ee95"
      },
      "cell_type": "code",
      "source": [
        "PATH="
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb.tgz  aclImdb.tgz.1  aclImdb.tgz.2  data  datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3TAseQXAeDDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}